{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LMxwmrFoS1ar",
        "outputId": "c5f1575a-2f58-4f97-ea7b-cf530989123e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y torch torchvision torchaudio\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_648Py3S9AB",
        "outputId": "aae9f3dc-c784-4ac0-9ba2-7e86974f2696"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: torch 2.9.0\n",
            "Uninstalling torch-2.9.0:\n",
            "  Successfully uninstalled torch-2.9.0\n",
            "Found existing installation: torchvision 0.24.0\n",
            "Uninstalling torchvision-0.24.0:\n",
            "  Successfully uninstalled torchvision-0.24.0\n",
            "\u001b[33mWARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mFound existing installation: torchaudio 2.9.0\n",
            "Uninstalling torchaudio-2.9.0:\n",
            "  Successfully uninstalled torchaudio-2.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# If nvidia-smi shows CUDA 12.4, use cu124 wheels:\n",
        "!pip install --no-cache-dir torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "smM-NJXQTApj",
        "outputId": "9f2b6203-aa97-416a-93f6-1e76d40377b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://download.pytorch.org/whl/cu124\n",
            "Collecting torch\n",
            "  Downloading https://download.pytorch.org/whl/cu124/torch-2.6.0%2Bcu124-cp312-cp312-linux_x86_64.whl.metadata (28 kB)\n",
            "Collecting torchvision\n",
            "  Downloading https://download.pytorch.org/whl/cu124/torchvision-0.21.0%2Bcu124-cp312-cp312-linux_x86_64.whl.metadata (6.1 kB)\n",
            "Collecting torchaudio\n",
            "  Downloading https://download.pytorch.org/whl/cu124/torchaudio-2.6.0%2Bcu124-cp312-cp312-linux_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m130.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m275.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m89.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m230.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m174.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m186.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m96.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m119.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparselt-cu12==0.6.2 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting nvidia-nccl-cu12==2.21.5 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m224.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.4.127 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m302.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m72.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton==3.2.0 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/triton-3.2.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Collecting sympy==1.13.1 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m246.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Downloading https://download.pytorch.org/whl/cu124/torch-2.6.0%2Bcu124-cp312-cp312-linux_x86_64.whl (768.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m768.4/768.4 MB\u001b[0m \u001b[31m212.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/cu124/nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl (150.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.1/150.1 MB\u001b[0m \u001b[31m200.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/triton-3.2.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (166.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.7/166.7 MB\u001b[0m \u001b[31m216.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/cu124/torchvision-0.21.0%2Bcu124-cp312-cp312-linux_x86_64.whl (7.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m255.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/cu124/torchaudio-2.6.0%2Bcu124-cp312-cp312-linux_x86_64.whl (3.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m233.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[33mWARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mInstalling collected packages: triton, nvidia-cusparselt-cu12, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchvision, torchaudio\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.5.0\n",
            "    Uninstalling triton-3.5.0:\n",
            "      Successfully uninstalled triton-3.5.0\n",
            "  Attempting uninstall: nvidia-cusparselt-cu12\n",
            "\u001b[33m    WARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m    Found existing installation: nvidia-cusparselt-cu12 0.7.1\n",
            "    Uninstalling nvidia-cusparselt-cu12-0.7.1:\n",
            "      Successfully uninstalled nvidia-cusparselt-cu12-0.7.1\n",
            "  Attempting uninstall: sympy\n",
            "\u001b[33m    WARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m    Found existing installation: sympy 1.13.3\n",
            "    Uninstalling sympy-1.13.3:\n",
            "      Successfully uninstalled sympy-1.13.3\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.8.90\n",
            "    Uninstalling nvidia-nvtx-cu12-12.8.90:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.8.90\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.8.93\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.8.93:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.8.93\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.27.5\n",
            "    Uninstalling nvidia-nccl-cu12-2.27.5:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.27.5\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.9.90\n",
            "    Uninstalling nvidia-curand-cu12-10.3.9.90:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.9.90\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.3.3.83\n",
            "    Uninstalling nvidia-cufft-cu12-11.3.3.83:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.3.3.83\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.8.90\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.8.90:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.8.90\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.8.93\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.8.93:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.8.93\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.8.90\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.8.90:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.8.90\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.8.4.1\n",
            "    Uninstalling nvidia-cublas-cu12-12.8.4.1:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.8.4.1\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "\u001b[33m    WARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m    Found existing installation: nvidia-cusparse-cu12 12.5.8.93\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.8.93:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.8.93\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "\u001b[33m    WARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m    Found existing installation: nvidia-cudnn-cu12 9.10.2.21\n",
            "    Uninstalling nvidia-cudnn-cu12-9.10.2.21:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.10.2.21\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "\u001b[33m    WARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m    Found existing installation: nvidia-cusolver-cu12 11.7.3.90\n",
            "    Uninstalling nvidia-cusolver-cu12-11.7.3.90:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.7.3.90\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-cusparselt-cu12-0.6.2 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 sympy-1.13.1 torch-2.6.0+cu124 torchaudio-2.6.0+cu124 torchvision-0.21.0+cu124 triton-3.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, torchaudio, torchvision\n",
        "print(torch.__version__, torchvision.__version__, torchaudio.__version__)\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        },
        "id": "LCgfii3QT_oQ",
        "outputId": "6b720d6d-2f1f-498c-a68e-a0a186beec57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "libcusparseLt.so.0: cannot open shared object file: No such file or directory",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-912179996.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorchaudio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorchaudio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"CUDA available:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    403\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mUSE_GLOBAL_DEPS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[0m_load_global_deps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa: F403\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: libcusparseLt.so.0: cannot open shared object file: No such file or directory",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y torch torchvision torchaudio \\\n",
        "  nvidia-cublas-cu12 nvidia-cudnn-cu12 nvidia-cusparse-cu12 nvidia-cusparselt-cu12\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJLS3cnnU1Bs",
        "outputId": "6467fc57-4674-45d1-e0d3-1e98857f81eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: torch 2.6.0+cu124\n",
            "Uninstalling torch-2.6.0+cu124:\n",
            "  Successfully uninstalled torch-2.6.0+cu124\n",
            "Found existing installation: torchvision 0.21.0+cu124\n",
            "Uninstalling torchvision-0.21.0+cu124:\n",
            "  Successfully uninstalled torchvision-0.21.0+cu124\n",
            "\u001b[33mWARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mFound existing installation: torchaudio 2.6.0+cu124\n",
            "Uninstalling torchaudio-2.6.0+cu124:\n",
            "  Successfully uninstalled torchaudio-2.6.0+cu124\n",
            "Found existing installation: nvidia-cublas-cu12 12.4.5.8\n",
            "Uninstalling nvidia-cublas-cu12-12.4.5.8:\n",
            "  Successfully uninstalled nvidia-cublas-cu12-12.4.5.8\n",
            "Found existing installation: nvidia-cudnn-cu12 9.1.0.70\n",
            "Uninstalling nvidia-cudnn-cu12-9.1.0.70:\n",
            "  Successfully uninstalled nvidia-cudnn-cu12-9.1.0.70\n",
            "Found existing installation: nvidia-cusparse-cu12 12.3.1.170\n",
            "Uninstalling nvidia-cusparse-cu12-12.3.1.170:\n",
            "  Successfully uninstalled nvidia-cusparse-cu12-12.3.1.170\n",
            "\u001b[33mWARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mFound existing installation: nvidia-cusparselt-cu12 0.6.2\n",
            "Uninstalling nvidia-cusparselt-cu12-0.6.2:\n",
            "  Successfully uninstalled nvidia-cusparselt-cu12-0.6.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --no-cache-dir torch==2.5.1 torchvision==0.20.1 torchaudio==2.5.1 \\\n",
        "  --index-url https://download.pytorch.org/whl/cu124\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lvr-UBNWU79Z",
        "outputId": "a77abbf8-6c04-49fb-bbf0-f94670efcfee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://download.pytorch.org/whl/cu124\n",
            "Collecting torch==2.5.1\n",
            "  Downloading https://download.pytorch.org/whl/cu124/torch-2.5.1%2Bcu124-cp312-cp312-linux_x86_64.whl (908.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m908.2/908.2 MB\u001b[0m \u001b[31m168.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.20.1\n",
            "  Downloading https://download.pytorch.org/whl/cu124/torchvision-0.20.1%2Bcu124-cp312-cp312-linux_x86_64.whl (7.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m265.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchaudio==2.5.1\n",
            "  Downloading https://download.pytorch.org/whl/cu124/torchaudio-2.5.1%2Bcu124-cp312-cp312-linux_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m310.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1) (4.15.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1) (12.4.127)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m193.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.4.5.8 (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m115.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1) (11.6.1.9)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m61.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1) (12.4.127)\n",
            "Collecting triton==3.1.0 (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/triton-3.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.6/209.6 MB\u001b[0m \u001b[31m163.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1) (75.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1) (1.13.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision==0.20.1) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision==0.20.1) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy==1.13.1->torch==2.5.1) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.5.1) (3.0.3)\n",
            "\u001b[33mWARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mInstalling collected packages: triton, nvidia-cusparse-cu12, nvidia-cublas-cu12, nvidia-cudnn-cu12, torch, torchvision, torchaudio\n",
            "  Attempting uninstall: triton\n",
            "\u001b[33m    WARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m    Found existing installation: triton 3.2.0\n",
            "    Uninstalling triton-3.2.0:\n",
            "      Successfully uninstalled triton-3.2.0\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cusparse-cu12-12.3.1.170 torch-2.5.1+cu124 torchaudio-2.5.1+cu124 torchvision-0.20.1+cu124 triton-3.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, torchvision, torchaudio\n",
        "print(\"torch:\", torch.__version__, \"| CUDA:\", torch.version.cuda)\n",
        "print(\"torchvision:\", torchvision.__version__)\n",
        "print(\"torchaudio:\", torchaudio.__version__)\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CEIHIIjyVfza",
        "outputId": "38d10c14-295b-4de8-c2df-a5aaca756cb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch: 2.5.1+cu124 | CUDA: 12.4\n",
            "torchvision: 0.20.1+cu124\n",
            "torchaudio: 2.5.1+cu124\n",
            "CUDA available: False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify GPU is attached\n",
        "!nvidia-smi\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ur3q1GH7WHoB",
        "outputId": "9099429b-f031-4b55-e9d6-907d3f62c329"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Nov  5 00:47:48 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   43C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Torch wheels that match CUDA 12.4\n",
        "!pip install --no-cache-dir torch==2.5.1 torchvision==0.20.1 torchaudio==2.5.1 \\\n",
        "  --index-url https://download.pytorch.org/whl/cu124\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1gsnLty-WJKM",
        "outputId": "2830ab05-13a5-4711-d002-64b6684cc5de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu124\n",
            "Requirement already satisfied: torch==2.5.1 in /usr/local/lib/python3.12/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision==0.20.1 in /usr/local/lib/python3.12/dist-packages (0.20.1+cu124)\n",
            "Requirement already satisfied: torchaudio==2.5.1 in /usr/local/lib/python3.12/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1) (4.15.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1) (3.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1) (75.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1) (1.13.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision==0.20.1) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision==0.20.1) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy==1.13.1->torch==2.5.1) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.5.1) (3.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check that CUDA is now available\n",
        "import torch, torchvision, torchaudio\n",
        "print(\"torch:\", torch.__version__, \"| CUDA:\", torch.version.cuda)\n",
        "print(\"torchvision:\", torchvision.__version__)\n",
        "print(\"torchaudio:\", torchaudio.__version__)\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5r8a8SgW-fx",
        "outputId": "e4c6a95d-4163-4fd5-b037-36c2d1a8e941"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch: 2.5.1+cu124 | CUDA: 12.4\n",
            "torchvision: 0.20.1+cu124\n",
            "torchaudio: 2.5.1+cu124\n",
            "CUDA available: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "BASE=\"/content/drive/MyDrive/enduro_dqn\"  # change if you like\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9poVNgLhXRDk",
        "outputId": "7e2766b6-fbe6-4822-8e82-f17e3e897ac6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --no-cache-dir torch==2.5.1 torchvision==0.20.1 torchaudio==2.5.1 \\\n",
        "  --index-url https://download.pytorch.org/whl/cu124\n",
        "\n",
        "!pip install -U \"ale-py\" \"gymnasium[atari]\" \"AutoROM[accept-rom-license]\" \\\n",
        "  tensorboard opencv-python --quiet\n",
        "\n",
        "from AutoROM import main\n",
        "install_path = \"/content/drive/MyDrive/AtariROMs\"\n",
        "main(source_file=None, install_dir=install_path, quiet=False, accept_license=True)\n",
        "\n",
        "import os, gymnasium as gym, ale_py\n",
        "os.environ[\"ALE_ROMS_DIR\"] = install_path\n",
        "gym.register_envs(ale_py)\n",
        "\n",
        "env = gym.make(\"ALE/Enduro-v5\", render_mode=\"rgb_array\")\n",
        "obs, info = env.reset()\n",
        "print(\"✅ Enduro OK:\", obs.shape, env.action_space)\n",
        "env.close()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTwuxbyhXVK9",
        "outputId": "76f9089b-e7e5-4f04-8083-20ceb02abaf9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu124\n",
            "Requirement already satisfied: torch==2.5.1 in /usr/local/lib/python3.12/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision==0.20.1 in /usr/local/lib/python3.12/dist-packages (0.20.1+cu124)\n",
            "Requirement already satisfied: torchaudio==2.5.1 in /usr/local/lib/python3.12/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1) (4.15.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1) (3.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1) (75.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1) (1.13.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision==0.20.1) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision==0.20.1) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy==1.13.1->torch==2.5.1) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.5.1) (3.0.3)\n",
            "AutoROM will download the Atari 2600 ROMs.\n",
            "They will be installed to:\n",
            "\t/content/drive/MyDrive/AtariROMs\n",
            "\n",
            "Existing ROMs will be overwritten.\n",
            "Loading roms from /content/drive/MyDrive/AtariROMs...\n",
            "✅ Enduro OK: (210, 160, 3) Discrete(9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== DQN for ALE/Enduro-v5 (PyTorch) ====\n",
        "# One cell: wrappers -> env -> replay buffer -> QNet -> train_dqn -> eval_and_gif\n",
        "\n",
        "import os, random, collections\n",
        "import numpy as np\n",
        "import cv2\n",
        "import gymnasium as gym\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "# ---------------- Wrappers: (210x160x3) -> (4,84,84) ----------------\n",
        "class GrayResize84(gym.ObservationWrapper):\n",
        "    \"\"\"Convert RGB to grayscale and resize to 84x84.\"\"\"\n",
        "    def __init__(self, env):\n",
        "        super().__init__(env)\n",
        "        self.observation_space = gym.spaces.Box(0, 255, shape=(84,84,1), dtype=np.uint8)\n",
        "    def observation(self, obs):\n",
        "        g = cv2.cvtColor(obs, cv2.COLOR_RGB2GRAY)\n",
        "        g = cv2.resize(g, (84,84), interpolation=cv2.INTER_AREA)\n",
        "        return g[..., None].astype(np.uint8)\n",
        "\n",
        "class ChannelFirst(gym.ObservationWrapper):\n",
        "    \"\"\"HWC -> CHW for PyTorch.\"\"\"\n",
        "    def __init__(self, env):\n",
        "        super().__init__(env)\n",
        "        self.observation_space = gym.spaces.Box(0,255,shape=(1,84,84),dtype=np.uint8)\n",
        "    def observation(self, obs):\n",
        "        return np.transpose(obs, (2,0,1))\n",
        "\n",
        "class FrameStack(gym.Wrapper):\n",
        "    \"\"\"Stack last k grayscale frames along channel axis.\"\"\"\n",
        "    def __init__(self, env, k=4):\n",
        "        super().__init__(env); self.k = k\n",
        "        c,h,w = env.observation_space.shape\n",
        "        self.observation_space = gym.spaces.Box(0,255,shape=(k*c,h,w),dtype=np.uint8)\n",
        "        self.frames = collections.deque(maxlen=k)\n",
        "    def reset(self, **kwargs):\n",
        "        obs, info = self.env.reset(**kwargs)\n",
        "        self.frames.clear()\n",
        "        for _ in range(self.k): self.frames.append(obs)\n",
        "        return self._obs(), info\n",
        "    def step(self, action):\n",
        "        obs, r, terminated, truncated, info = self.env.step(action)\n",
        "        self.frames.append(obs)\n",
        "        return self._obs(), r, terminated, truncated, info\n",
        "    def _obs(self):\n",
        "        return np.concatenate(list(self.frames), axis=0)\n",
        "\n",
        "def make_env(seed=0, full_action_space=False, render_mode=None):\n",
        "    \"\"\"Create Enduro env with preprocessing and (optionally) full action space.\"\"\"\n",
        "    env = gym.make(\"ALE/Enduro-v5\", render_mode=render_mode, full_action_space=full_action_space)\n",
        "    env = GrayResize84(env)\n",
        "    env = ChannelFirst(env)\n",
        "    env = FrameStack(env, k=4)\n",
        "    env.reset(seed=seed)\n",
        "    return env\n",
        "\n",
        "# ---------------- Replay Buffer ----------------\n",
        "T = collections.namedtuple(\"T\", [\"s\",\"a\",\"r\",\"s2\",\"d\"])\n",
        "class ReplayBuffer:\n",
        "    def __init__(self, capacity=100_000):\n",
        "        self.buf = collections.deque(maxlen=capacity)\n",
        "    def __len__(self):\n",
        "        return len(self.buf)\n",
        "    def add(self, *args):\n",
        "        self.buf.append(T(*args))\n",
        "    def sample(self, n):\n",
        "        batch = random.sample(self.buf, n)\n",
        "        s  = np.stack([b.s for b in batch])\n",
        "        a  = np.array([b.a for b in batch])\n",
        "        r  = np.array([b.r for b in batch], dtype=np.float32)\n",
        "        s2 = np.stack([b.s2 for b in batch])\n",
        "        d  = np.array([b.d for b in batch], dtype=np.float32)\n",
        "        return s,a,r,s2,d\n",
        "\n",
        "# ---------------- Q-Network (Nature CNN) ----------------\n",
        "class QNet(nn.Module):\n",
        "    def __init__(self, in_ch, n_actions):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(in_ch, 32, kernel_size=8, stride=4), nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, kernel_size=4, stride=2), nn.ReLU(),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, stride=1), nn.ReLU(),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(3136, 512), nn.ReLU(),\n",
        "            nn.Linear(512, n_actions),\n",
        "        )\n",
        "    def forward(self, x):    # x: uint8 tensor [B, C, H, W]\n",
        "        return self.net(x / 255.0)\n",
        "\n",
        "# ---------------- Training ----------------\n",
        "def train_dqn(\n",
        "    seed=0,\n",
        "    episodes=500,\n",
        "    max_steps=18000,\n",
        "    buffer_capacity=100_000,\n",
        "    batch_size=32,\n",
        "    lr=2.5e-4,\n",
        "    gamma=0.99,\n",
        "    start_learn=50_000,\n",
        "    target_update=10_000,\n",
        "    eps_start=1.0,\n",
        "    eps_end=0.01,\n",
        "    eps_decay_steps=200_000,\n",
        "    reward_clip=True,\n",
        "    full_action_space=False,\n",
        "    log_dir=\"/content/runs/enduro_dqn\",\n",
        "    ckpt_dir=\"/content/checkpoints\"\n",
        "):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    env = make_env(seed=seed, full_action_space=full_action_space, render_mode=None)\n",
        "    n_actions = env.action_space.n\n",
        "    in_ch = env.observation_space.shape[0]\n",
        "\n",
        "    q  = QNet(in_ch, n_actions).to(device)\n",
        "    qt = QNet(in_ch, n_actions).to(device)\n",
        "    qt.load_state_dict(q.state_dict())\n",
        "\n",
        "    opt = optim.Adam(q.parameters(), lr=lr)\n",
        "    rb  = ReplayBuffer(buffer_capacity)\n",
        "    writer = SummaryWriter(log_dir=log_dir)\n",
        "    rng = np.random.RandomState(seed)\n",
        "    global_step = 0\n",
        "\n",
        "    def eps_by_step(step):\n",
        "        frac = min(1.0, step / float(eps_decay_steps))\n",
        "        return max(eps_end, eps_start * (1.0 - frac) + eps_end * frac)\n",
        "\n",
        "    ep_returns, ep_lengths = [], []\n",
        "\n",
        "    for ep in range(episodes):\n",
        "        s, _ = env.reset()\n",
        "        done = False\n",
        "        ep_ret, ep_len = 0.0, 0\n",
        "\n",
        "        for t in range(max_steps):\n",
        "            eps = eps_by_step(global_step)\n",
        "            if rng.rand() < eps:\n",
        "                a = env.action_space.sample()\n",
        "            else:\n",
        "                with torch.no_grad():\n",
        "                    qs = q(torch.tensor(s[None], device=device, dtype=torch.float32))\n",
        "                    a = int(qs.argmax(dim=1).item())\n",
        "\n",
        "            s2, r, terminated, truncated, _ = env.step(a)\n",
        "            done = terminated or truncated\n",
        "\n",
        "            rr = np.sign(r) if reward_clip else r\n",
        "            rb.add(s, a, rr, s2, float(done))\n",
        "\n",
        "            s = s2\n",
        "            ep_ret += r\n",
        "            ep_len += 1\n",
        "            global_step += 1\n",
        "\n",
        "            # Learn\n",
        "            if len(rb) >= start_learn:\n",
        "                S,A,R,S2,D = rb.sample(batch_size)\n",
        "                S  = torch.tensor(S,  dtype=torch.float32, device=device)\n",
        "                A  = torch.tensor(A,  dtype=torch.int64,   device=device)\n",
        "                R  = torch.tensor(R,  dtype=torch.float32, device=device)\n",
        "                S2 = torch.tensor(S2, dtype=torch.float32, device=device)\n",
        "                D  = torch.tensor(D,  dtype=torch.float32, device=device)\n",
        "\n",
        "                with torch.no_grad():\n",
        "                    # Double DQN target\n",
        "                    next_a = q(S2).argmax(dim=1)\n",
        "                    target = R + (1.0 - D) * gamma * qt(S2).gather(1, next_a.unsqueeze(1)).squeeze(1)\n",
        "\n",
        "                pred = q(S).gather(1, A.unsqueeze(1)).squeeze(1)\n",
        "                loss = nn.SmoothL1Loss()(pred, target)\n",
        "\n",
        "                opt.zero_grad()\n",
        "                loss.backward()\n",
        "                nn.utils.clip_grad_norm_(q.parameters(), 10.0)\n",
        "                opt.step()\n",
        "\n",
        "                if global_step % target_update == 0:\n",
        "                    qt.load_state_dict(q.state_dict())\n",
        "\n",
        "                if global_step % 1000 == 0:\n",
        "                    writer.add_scalar(\"train/loss\", loss.item(), global_step)\n",
        "                    writer.add_scalar(\"train/epsilon\", eps, global_step)\n",
        "                    writer.add_scalar(\"buffer/size\", len(rb), global_step)\n",
        "\n",
        "            if done:\n",
        "                break\n",
        "\n",
        "        ep_returns.append(ep_ret)\n",
        "        ep_lengths.append(ep_len)\n",
        "\n",
        "        if (ep + 1) % 10 == 0:\n",
        "            avg_r = float(np.mean(ep_returns[-10:]))\n",
        "            avg_len = float(np.mean(ep_lengths[-10:]))\n",
        "            print(f\"Ep {ep+1}/{episodes} | avgR@10={avg_r:.1f} | avgLen@10={avg_len:.0f} | eps={eps:.3f}\")\n",
        "            writer.add_scalar(\"eval/avg_return_last10\", avg_r, ep+1)\n",
        "            writer.add_scalar(\"eval/avg_length_last10\", avg_len, ep+1)\n",
        "\n",
        "    env.close()\n",
        "    os.makedirs(ckpt_dir, exist_ok=True)\n",
        "    torch.save(q.state_dict(), os.path.join(ckpt_dir, \"enduro_dqn.pt\"))\n",
        "    np.savez(os.path.join(ckpt_dir, \"logs.npz\"),\n",
        "             rewards=np.array(ep_returns), lengths=np.array(ep_lengths))\n",
        "    writer.close()\n",
        "    print(f\"✅ Saved model & logs to {ckpt_dir}\")\n",
        "\n",
        "# ---------------- Tiny eval + GIF helper (optional) ----------------\n",
        "import imageio\n",
        "\n",
        "def eval_and_gif(ckpt=\"/content/checkpoints/enduro_dqn.pt\", episodes=3, gif_path=\"/content/enduro_demo.gif\"):\n",
        "    env = make_env(render_mode=\"rgb_array\")\n",
        "    n_actions = env.action_space.n; in_ch = env.observation_space.shape[0]\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    q = QNet(in_ch, n_actions).to(device)\n",
        "    q.load_state_dict(torch.load(ckpt, map_location=device))\n",
        "    q.eval()\n",
        "\n",
        "    returns, frames = [], []\n",
        "    for ep in range(episodes):\n",
        "        s, _ = env.reset(); done = False; ep_ret = 0.0\n",
        "        while not done:\n",
        "            with torch.no_grad():\n",
        "                a = int(q(torch.tensor(s[None], device=device, dtype=torch.float32)).argmax(dim=1).item())\n",
        "            s, r, term, trunc, _ = env.step(a)\n",
        "            ep_ret += r; done = term or trunc\n",
        "            if ep == 0:  # capture first episode for the GIF\n",
        "                frames.append(env.envs[0].render())\n",
        "        returns.append(ep_ret)\n",
        "    env.close()\n",
        "    imageio.mimsave(gif_path, frames, fps=30)\n",
        "    print(f\"Avg return: {np.mean(returns):.1f} | Saved GIF to {gif_path}\")\n"
      ],
      "metadata": {
        "id": "EhanBvrnYB4f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Expect (4,84,84)\n",
        "wrapped = make_env(render_mode=None)\n",
        "x, _ = wrapped.reset()\n",
        "print(\"Wrapped obs:\", x.shape)\n",
        "wrapped.close()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MxLa8g1kYJge",
        "outputId": "8349045c-8063-4e1f-fd80-c5c7c0c9b87d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading roms from /content/drive/MyDrive/AtariROMs...\n",
            "Loading roms from /content/drive/MyDrive/AtariROMs...\n",
            "Wrapped obs: (4, 84, 84)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os; os.makedirs(f\"{BASE}/runs\", exist_ok=True); os.makedirs(f\"{BASE}/ckpts\", exist_ok=True)\n",
        "\n",
        "train_dqn(\n",
        "    seed=0,\n",
        "    episodes=500,              # increase to 1000–2000 for stronger results\n",
        "    max_steps=18000,\n",
        "    buffer_capacity=100_000,\n",
        "    batch_size=32,\n",
        "    lr=2.5e-4,\n",
        "    gamma=0.99,\n",
        "    start_learn=50_000,\n",
        "    target_update=10_000,\n",
        "    eps_start=1.0, eps_end=0.01, eps_decay_steps=200_000,\n",
        "    reward_clip=True,\n",
        "    full_action_space=False,\n",
        "    log_dir=f\"{BASE}/runs/baseline\",\n",
        "    ckpt_dir=f\"{BASE}/ckpts/baseline\"\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VSa3pFc7YUNI",
        "outputId": "c0a17353-ebc5-489e-cc7c-2636d63c9220"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading roms from /content/drive/MyDrive/AtariROMs...\n",
            "Loading roms from /content/drive/MyDrive/AtariROMs...\n",
            "Ep 10/500 | avgR@10=0.0 | avgLen@10=3328 | eps=0.835\n",
            "Ep 20/500 | avgR@10=0.0 | avgLen@10=3328 | eps=0.671\n",
            "Ep 30/500 | avgR@10=0.0 | avgLen@10=3328 | eps=0.506\n",
            "Ep 40/500 | avgR@10=0.0 | avgLen@10=3328 | eps=0.341\n",
            "Ep 50/500 | avgR@10=0.0 | avgLen@10=3328 | eps=0.176\n",
            "Ep 60/500 | avgR@10=0.0 | avgLen@10=3328 | eps=0.012\n",
            "Ep 70/500 | avgR@10=26.1 | avgLen@10=3328 | eps=0.010\n",
            "Ep 80/500 | avgR@10=30.3 | avgLen@10=3328 | eps=0.010\n",
            "Ep 90/500 | avgR@10=20.9 | avgLen@10=3328 | eps=0.010\n",
            "Ep 100/500 | avgR@10=23.1 | avgLen@10=3328 | eps=0.010\n",
            "Ep 110/500 | avgR@10=28.2 | avgLen@10=3328 | eps=0.010\n",
            "Ep 120/500 | avgR@10=32.3 | avgLen@10=3328 | eps=0.010\n",
            "Ep 130/500 | avgR@10=12.8 | avgLen@10=3328 | eps=0.010\n",
            "Ep 140/500 | avgR@10=17.5 | avgLen@10=3328 | eps=0.010\n",
            "Ep 150/500 | avgR@10=17.8 | avgLen@10=3328 | eps=0.010\n",
            "Ep 160/500 | avgR@10=29.6 | avgLen@10=3328 | eps=0.010\n",
            "Ep 170/500 | avgR@10=24.5 | avgLen@10=3328 | eps=0.010\n",
            "Ep 180/500 | avgR@10=21.8 | avgLen@10=3328 | eps=0.010\n",
            "Ep 190/500 | avgR@10=24.3 | avgLen@10=3328 | eps=0.010\n",
            "Ep 200/500 | avgR@10=21.8 | avgLen@10=3328 | eps=0.010\n",
            "Ep 210/500 | avgR@10=32.0 | avgLen@10=3328 | eps=0.010\n",
            "Ep 220/500 | avgR@10=17.7 | avgLen@10=3328 | eps=0.010\n",
            "Ep 230/500 | avgR@10=19.9 | avgLen@10=3328 | eps=0.010\n",
            "Ep 240/500 | avgR@10=30.5 | avgLen@10=3328 | eps=0.010\n",
            "Ep 250/500 | avgR@10=30.1 | avgLen@10=3328 | eps=0.010\n",
            "Ep 260/500 | avgR@10=26.2 | avgLen@10=3328 | eps=0.010\n",
            "Ep 270/500 | avgR@10=28.9 | avgLen@10=3328 | eps=0.010\n",
            "Ep 280/500 | avgR@10=13.2 | avgLen@10=3328 | eps=0.010\n",
            "Ep 290/500 | avgR@10=26.2 | avgLen@10=3328 | eps=0.010\n",
            "Ep 300/500 | avgR@10=18.9 | avgLen@10=3328 | eps=0.010\n",
            "Ep 310/500 | avgR@10=25.5 | avgLen@10=3328 | eps=0.010\n",
            "Ep 320/500 | avgR@10=25.6 | avgLen@10=3328 | eps=0.010\n",
            "Ep 330/500 | avgR@10=22.5 | avgLen@10=3328 | eps=0.010\n",
            "Ep 340/500 | avgR@10=23.0 | avgLen@10=3328 | eps=0.010\n",
            "Ep 350/500 | avgR@10=24.0 | avgLen@10=3328 | eps=0.010\n",
            "Ep 360/500 | avgR@10=25.8 | avgLen@10=3328 | eps=0.010\n",
            "Ep 370/500 | avgR@10=17.1 | avgLen@10=3328 | eps=0.010\n",
            "Ep 380/500 | avgR@10=1.0 | avgLen@10=3328 | eps=0.010\n",
            "Ep 390/500 | avgR@10=2.8 | avgLen@10=3328 | eps=0.010\n",
            "Ep 400/500 | avgR@10=7.6 | avgLen@10=3328 | eps=0.010\n",
            "Ep 410/500 | avgR@10=38.6 | avgLen@10=3328 | eps=0.010\n",
            "Ep 420/500 | avgR@10=74.7 | avgLen@10=3328 | eps=0.010\n",
            "Ep 430/500 | avgR@10=133.2 | avgLen@10=3328 | eps=0.010\n",
            "Ep 440/500 | avgR@10=158.2 | avgLen@10=3661 | eps=0.010\n",
            "Ep 450/500 | avgR@10=196.0 | avgLen@10=3994 | eps=0.010\n",
            "Ep 460/500 | avgR@10=244.6 | avgLen@10=4659 | eps=0.010\n",
            "Ep 470/500 | avgR@10=264.8 | avgLen@10=4992 | eps=0.010\n",
            "Ep 480/500 | avgR@10=348.0 | avgLen@10=5990 | eps=0.010\n",
            "Ep 490/500 | avgR@10=375.8 | avgLen@10=6323 | eps=0.010\n",
            "Ep 500/500 | avgR@10=391.2 | avgLen@10=6323 | eps=0.010\n",
            "✅ Saved model & logs to /content/drive/MyDrive/enduro_dqn/ckpts/baseline\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U \"ale-py\" \"gymnasium[atari]\" \"AutoROM[accept-rom-license]\" --quiet\n",
        "\n",
        "from AutoROM import main\n",
        "import os, gymnasium as gym, ale_py\n",
        "\n",
        "# ROM install path (same as before)\n",
        "install_path = \"/content/drive/MyDrive/AtariROMs\"\n",
        "\n",
        "# Download ROMs (skip if already present)\n",
        "main(source_file=None, install_dir=install_path, quiet=False, accept_license=True)\n",
        "\n",
        "# Register the ALE environments\n",
        "os.environ[\"ALE_ROMS_DIR\"] = install_path\n",
        "gym.register_envs(ale_py)\n",
        "\n",
        "# Quick check\n",
        "env = gym.make(\"ALE/Enduro-v5\", render_mode=\"rgb_array\")\n",
        "obs, info = env.reset()\n",
        "print(\"✅ ALE environments registered | Enduro OK | obs shape:\", obs.shape)\n",
        "env.close()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20CtoRgIxisa",
        "outputId": "6fdd9e12-a929-4848-e4f1-949cb5abdf5a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/434.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m430.1/434.7 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.7/434.7 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for AutoROM.accept-rom-license (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "AutoROM will download the Atari 2600 ROMs.\n",
            "They will be installed to:\n",
            "\t/content/drive/MyDrive/AtariROMs\n",
            "\n",
            "Existing ROMs will be overwritten.\n",
            "Loading roms from /content/drive/MyDrive/AtariROMs...\n",
            "✅ ALE environments registered | Enduro OK | obs shape: (210, 160, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===================== SELF-CONTAINED TEST + MP4 EXPORT =====================\n",
        "# - Registers ALE Atari environments\n",
        "# - Defines preprocessing wrappers + make_env + QNet (same as training shape)\n",
        "# - Loads your checkpoint and records an MP4 with Gymnasium's RecordVideo\n",
        "\n",
        "import os, collections, numpy as np, cv2, torch, torch.nn as nn\n",
        "import gymnasium as gym\n",
        "from gymnasium.wrappers import RecordVideo\n",
        "import ale_py\n",
        "\n",
        "# ---------- 0) Ensure ALE namespace is registered ----------\n",
        "# (Assumes you already installed ROMs and set the same folder earlier)\n",
        "os.environ.setdefault(\"ALE_ROMS_DIR\", \"/content/drive/MyDrive/AtariROMs\")\n",
        "gym.register_envs(ale_py)\n",
        "\n",
        "# ---------- 1) Preprocessing wrappers ----------\n",
        "class GrayResize84(gym.ObservationWrapper):\n",
        "    def __init__(self, env):\n",
        "        super().__init__(env)\n",
        "        self.observation_space = gym.spaces.Box(0,255,shape=(84,84,1),dtype=np.uint8)\n",
        "    def observation(self, obs):\n",
        "        g = cv2.cvtColor(obs, cv2.COLOR_RGB2GRAY)\n",
        "        g = cv2.resize(g, (84,84), interpolation=cv2.INTER_AREA)\n",
        "        return g[...,None].astype(np.uint8)\n",
        "\n",
        "class ChannelFirst(gym.ObservationWrapper):\n",
        "    def __init__(self, env):\n",
        "        super().__init__(env)\n",
        "        self.observation_space = gym.spaces.Box(0,255,shape=(1,84,84),dtype=np.uint8)\n",
        "    def observation(self, obs):\n",
        "        return np.transpose(obs, (2,0,1))  # HWC->CHW\n",
        "\n",
        "class FrameStack(gym.Wrapper):\n",
        "    def __init__(self, env, k=4):\n",
        "        super().__init__(env); self.k = k\n",
        "        c,h,w = env.observation_space.shape\n",
        "        self.observation_space = gym.spaces.Box(0,255,shape=(k*c,h,w),dtype=np.uint8)\n",
        "        self.frames = collections.deque(maxlen=k)\n",
        "    def reset(self, **kwargs):\n",
        "        obs, info = self.env.reset(**kwargs)\n",
        "        self.frames.clear()\n",
        "        for _ in range(self.k): self.frames.append(obs)\n",
        "        return self._get(), info\n",
        "    def step(self, action):\n",
        "        obs, r, terminated, truncated, info = self.env.step(action)\n",
        "        self.frames.append(obs)\n",
        "        return self._get(), r, terminated, truncated, info\n",
        "    def _get(self):\n",
        "        return np.concatenate(list(self.frames), axis=0)\n",
        "\n",
        "def make_env(seed=0, full_action_space=False, render_mode=None):\n",
        "    env = gym.make(\"ALE/Enduro-v5\", render_mode=render_mode, full_action_space=full_action_space)\n",
        "    env = GrayResize84(env)\n",
        "    env = ChannelFirst(env)\n",
        "    env = FrameStack(env, k=4)\n",
        "    env.reset(seed=seed)\n",
        "    return env\n",
        "\n",
        "# ---------- 2) Q-network (same architecture you trained) ----------\n",
        "class QNet(nn.Module):\n",
        "    def __init__(self, in_ch, n_actions):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(in_ch, 32, kernel_size=8, stride=4), nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, kernel_size=4, stride=2), nn.ReLU(),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, stride=1), nn.ReLU(),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(3136, 512), nn.ReLU(),\n",
        "            nn.Linear(512, n_actions),\n",
        "        )\n",
        "    def forward(self, x):  # x uint8 [B,C,H,W]\n",
        "        return self.net(x/255.0)\n",
        "\n",
        "# ---------- 3) Playback + MP4 recording ----------\n",
        "def record_mp4(\n",
        "    ckpt=\"/content/drive/MyDrive/enduro_dqn/ckpts/baseline/enduro_dqn.pt\",\n",
        "    video_dir=\"/content/drive/MyDrive/enduro_dqn/video\",\n",
        "    seed=0\n",
        "):\n",
        "    os.makedirs(video_dir, exist_ok=True)\n",
        "\n",
        "    # Recording env (raw RGB frames)\n",
        "    base_env = gym.make(\"ALE/Enduro-v5\", render_mode=\"rgb_array\")\n",
        "    rec_env = RecordVideo(base_env, video_folder=video_dir, name_prefix=\"enduro_dqn\")\n",
        "    obs_raw, _ = rec_env.reset(seed=seed)\n",
        "\n",
        "    # Policy env (preprocessed frames for the model)\n",
        "    pol_env = make_env(seed=seed, render_mode=None)\n",
        "    n_actions = pol_env.action_space.n\n",
        "    in_ch = pol_env.observation_space.shape[0]\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    q = QNet(in_ch, n_actions).to(device)\n",
        "    q.load_state_dict(torch.load(ckpt, map_location=device))\n",
        "    q.eval()\n",
        "\n",
        "    s, _ = pol_env.reset(seed=seed)\n",
        "    done = False\n",
        "    ep_ret = 0.0\n",
        "    while not done:\n",
        "        with torch.no_grad():\n",
        "            a = int(q(torch.tensor(s[None], device=device, dtype=torch.float32)).argmax(dim=1).item())\n",
        "        # step both envs with same action\n",
        "        obs_raw, r, term, trunc, _ = rec_env.step(a)\n",
        "        s, r2, t2, tr2, _ = pol_env.step(a)\n",
        "        assert r == r2\n",
        "        ep_ret += r\n",
        "        done = term or trunc or t2 or tr2\n",
        "\n",
        "    rec_env.close(); pol_env.close()\n",
        "    print(f\"Episode return: {ep_ret:.1f}\")\n",
        "    print(f\"MP4 saved in: {video_dir}\")\n",
        "\n",
        "# ---------- 4) Run it ----------\n",
        "record_mp4()\n",
        "# ============================================================================\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TmLiZliMyAtg",
        "outputId": "4da4bb13-06da-440e-b8ac-54a6d7ddbd82"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading roms from /content/drive/MyDrive/AtariROMs...\n",
            "Loading roms from /content/drive/MyDrive/AtariROMs...\n",
            "Loading roms from /content/drive/MyDrive/AtariROMs...\n",
            "Loading roms from /content/drive/MyDrive/AtariROMs...\n",
            "Loading roms from /content/drive/MyDrive/AtariROMs...\n",
            "Episode return: 448.0\n",
            "MP4 saved in: /content/drive/MyDrive/enduro_dqn/video\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np, os\n",
        "\n",
        "BASE = \"/content/drive/MyDrive/enduro_dqn\"  # change if different\n",
        "data = np.load(f\"{BASE}/ckpts/baseline/logs.npz\")\n",
        "rewards, lengths = data[\"rewards\"], data[\"lengths\"]\n",
        "\n",
        "def last_k_avg(arr, k=100):\n",
        "    k = min(k, len(arr))\n",
        "    return float(np.mean(arr[-k:]))\n",
        "\n",
        "print(\"Episodes logged:\", len(rewards))\n",
        "print(\"Last-100 avg return:\", last_k_avg(rewards, 100))\n",
        "print(\"Last-100 avg steps:\", last_k_avg(lengths, 100))\n",
        "print(\"Overall mean return:\", float(np.mean(rewards)))\n",
        "print(\"Overall mean steps:\", float(np.mean(lengths)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1EkOc7PfenRH",
        "outputId": "7a79f6ec-6cdd-485c-c2b4-b9693bcffb4e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episodes logged: 500\n",
            "Last-100 avg return: 222.51\n",
            "Last-100 avg steps: 4592.64\n",
            "Overall mean return: 59.492\n",
            "Overall mean steps: 3580.928\n"
          ]
        }
      ]
    }
  ]
}